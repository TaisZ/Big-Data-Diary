# Big Data 学习日历
因为~~个人兴趣~~毕业项目的需要，特开一个repo来记录大数据的学习过程。大数据的目的就是为了解决在多台机器上存取和处理海量数据这两个问题。

算是给自己挖了个大坑，不知道猴年马月可以参透大数据和分布式计算。此帖只是学习目录，后面会陆续更新每个知识点的详细学习日记

## 1. 分布式存储
* HDFS (Hadoop Distributed File System）
* Hbase

## 2. 分布式计算
### 2.1 离线计算/批处理
>大家在做 JavaEE 开发时，比如：电商后台统计所有订单的签收情况，订单签收情况来源于订单的物流轨迹，而查询订单的物流轨迹又需要调用对应物流公司提供的 API，而物流公司为了防止频繁调用 API 发生 DDOS，常常对接口 API 进行调用的限制（例如：1 秒只允许查询一次）。所以，对于大量的订单没有办法立即获得统计结果；因此，对于这样耗时比较长的计算，就会写成一个定时任务，每天晚上执行一次计算，第二天看结果。

大数据领域的离线计算和上面的例子类似，我们写完了一个离线计算程序（MapReduce 程序或 Spark 程序）之后，提交到服务器集群上，然后它就开始运行，几个小时之后或者第二天获取运行结果。与 JavaEE 的定时任务不同的是：大数据领域计算的数据量是巨大的，通常是 PB 级别的，只用单机的定时任务来处理数据那猴年马月也计算不完，而大数据领域使用分布式的离线计算则可以大大地减少时间。
* MapReduce
* yarn
* Hive
* Pig
* Sqoop
* Flume
* Scala
* Spark
### 2.2 实时计算/流计算  
>像统计过去一年订单中某件商品的销售总额这类需求，对实时性要求不高，一般会使用离线计算程序（mapreduce）来计算。但是，像网站访问的 PV，UV，每天各小时的流量这种类型的需求，hadoop 的 mapreduce 框架或者叫编程模型的计算效率就有点低。所以为了应对实时性较高的需求就需要学习一些实时计算框架。
* Storm
* SparkStreaming
* Kafka
* Zookeeper
  